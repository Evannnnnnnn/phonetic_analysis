<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Phonetic Analysis Studio</title>

  <style>
/* ========== BASE ========== */
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: 'Poppins', sans-serif;
  background: linear-gradient(-45deg, #667eea, #764ba2, #89f7fe, #66a6ff);
  background-size: 400% 400%;
  animation: gradientShift 15s ease infinite;
  min-height: 100vh;
  padding: 40px 20px;
  display: flex;
  justify-content: center;
  align-items: flex-start;
  color: #222;
}
@keyframes gradientShift {
  0% {background-position: 0% 50%;}
  50% {background-position: 100% 50%;}
  100% {background-position: 0% 50%;}
}

/* ========== CONTAINER ========== */
.container {
  max-width: 900px;
  width: 100%;
  background: rgba(255, 255, 255, 0.2);
  border-radius: 25px;
  backdrop-filter: blur(15px);
  box-shadow: 0 8px 35px rgba(0, 0, 0, 0.2);
  overflow: hidden;
  transition: all 0.4s ease;
}

/* ========== HEADER ========== */
.header {
  background: linear-gradient(135deg, #4facfe, #00f2fe);
  color: white;
  text-align: center;
  padding: 45px 20px;
}
.header h1 {
  font-size: 2.8em;
  text-shadow: 0 2px 6px rgba(0,0,0,0.3);
}
.header p { margin-top: 10px; opacity: 0.9; }

/* ========== BUTTONS ========== */
.recording-section {
  text-align: center;
  margin: 35px 0;
}
.btn {
  background: rgba(255,255,255,0.15);
  border: 2px solid rgba(255,255,255,0.4);
  color: white;
  padding: 14px 35px;
  font-size: 18px;
  border-radius: 50px;
  cursor: pointer;
  margin: 10px;
  transition: all 0.3s ease;
  box-shadow: 0 8px 20px rgba(0,0,0,0.25);
  backdrop-filter: blur(8px);
}
.btn:hover {
  background: rgba(255,255,255,0.35);
  transform: translateY(-2px);
}
.btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
  transform: none;
}
.btn.recording {
  background: linear-gradient(145deg, #ff4b2b, #ff416c);
  box-shadow: 0 0 25px rgba(255, 65, 108, 0.6);
  animation: pulse 1.5s infinite;
}
@keyframes pulse {
  0% { box-shadow: 0 0 10px rgba(255,65,108,0.5); }
  50% { box-shadow: 0 0 30px rgba(255,65,108,1); }
  100% { box-shadow: 0 0 10px rgba(255,65,108,0.5); }
}

/* ========== STATUS ========== */
.status {
  text-align: center;
  font-weight: 600;
  margin: 10px auto;
  padding: 12px;
  border-radius: 10px;
  width: fit-content;
  min-width: 250px;
  transition: all 0.3s ease;
}
.status.ready { background: rgba(46, 204, 113, 0.2); color: #1b5e20; }
.status.recording { background: rgba(231, 76, 60, 0.2); color: #c0392b; }
.status.processing { background: rgba(241, 196, 15, 0.2); color: #f39c12; }
.status.error { background: rgba(231, 76, 60, 0.3); color: #c0392b; }

/* ========== RESULTS PANEL ========== */
.results {
  padding: 40px;
  background: rgba(255,255,255,0.45);
  border-radius: 20px;
  margin: 20px;
  animation: fadeUp 0.7s ease;
}
.hidden { display: none; }
@keyframes fadeUp {
  from { opacity: 0; transform: translateY(30px); }
  to { opacity: 1; transform: translateY(0); }
}

/* ========== SECTIONS ========== */
.transcription {
  background: rgba(255,255,255,0.8);
  border-radius: 15px;
  padding: 20px;
  margin-bottom: 25px;
  box-shadow: 0 3px 15px rgba(0,0,0,0.1);
}
.transcription h3 { margin-bottom: 10px; }

.pronunciation-comparison {
  background: rgba(255,255,255,0.6);
  border-radius: 15px;
  padding: 20px;
  margin-top: 10px;
  border: 1px solid rgba(255,255,255,0.3);
  box-shadow: 0 3px 15px rgba(0,0,0,0.08);
}
.pronunciation-label {
  font-weight: 600;
  width: 160px;
}
.pronunciation-row {
  display: flex; align-items: center; margin: 10px 0;
}
.pronunciation-text {
  flex: 1;
  font-family: 'JetBrains Mono', monospace;
  font-size: 1.1em;
  padding: 8px 12px;
  background: rgba(255,255,255,0.9);
  border-radius: 10px;
}

/* Phoneme highlights */
.phoneme-correct { color: #2e7d32; }
.phoneme-error { color: #c62828; border-bottom: 2px solid #e57373; }

/* Conversation History Section */
.conversation-history {
  background: rgba(255,255,255,0.6);
  border-radius: 15px;
  padding: 20px;
  margin: 20px 0;
  border: 1px solid rgba(255,255,255,0.3);
  box-shadow: 0 3px 15px rgba(0,0,0,0.08);
}

.conversation-history h3 {
  margin-bottom: 15px;
  color: #495057;
  font-size: 1.1em;
}

.conversation-list {
  max-height: 300px;
  overflow-y: auto;
  padding: 10px;
  background: rgba(255,255,255,0.9);
  border-radius: 10px;
}

.conversation-item {
  margin-bottom: 15px;
  padding: 10px;
  border-radius: 8px;
  border-left: 4px solid #4facfe;
}

.conversation-item.user {
  background: rgba(79, 172, 254, 0.1);
  border-left-color: #4facfe;
}

.conversation-item.assistant {
  background: rgba(46, 204, 113, 0.1);
  border-left-color: #2ecc71;
}

.conversation-item .role {
  font-weight: 600;
  font-size: 0.9em;
  margin-bottom: 5px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.conversation-item.user .role {
  color: #4facfe;
}

.conversation-item.assistant .role {
  color: #2ecc71;
}

.conversation-item .content {
  color: #333;
  line-height: 1.4;
}

.conversation-item .timestamp {
  font-size: 0.8em;
  color: #666;
  margin-top: 5px;
}

/* AI Response Section */
.ai-response {
  background: rgba(255,255,255,0.6);
  border-radius: 15px;
  padding: 20px;
  margin: 20px 0;
  border: 1px solid rgba(255,255,255,0.3);
  box-shadow: 0 3px 15px rgba(0,0,0,0.08);
}

.ai-response h3 {
  margin-bottom: 15px;
  color: #495057;
  font-size: 1.1em;
}

.ai-text {
  background: rgba(255,255,255,0.9);
  padding: 15px;
  border-radius: 10px;
  margin-bottom: 15px;
  font-style: italic;
  color: #333;
  line-height: 1.5;
}

.play-btn {
  background: linear-gradient(135deg, #4facfe, #00f2fe);
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 25px;
  cursor: pointer;
  font-size: 14px;
  transition: all 0.3s ease;
}

.play-btn:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 15px rgba(79, 172, 254, 0.4);
}

.play-btn:disabled {
  background: #ccc;
  cursor: not-allowed;
  transform: none;
  box-shadow: none;
}


.stat-item {
  display: flex;
  justify-content: space-between;
  padding: 8px 0;
  border-bottom: 1px solid rgba(0,0,0,0.1);
}

.stat-item:last-child {
  border-bottom: none;
}

.stat-label {
  font-weight: 600;
  color: #495057;
}

.stat-value {
  color: #4facfe;
  font-weight: 500;
}

/* Phoneme highlighting */
.phoneme {
  display: inline-block;
  padding: 2px 4px;
  margin: 1px;
  border-radius: 3px;
  font-family: 'Courier New', monospace;
  font-size: 0.9em;
  transition: all 0.2s ease;
}

.phoneme.low-confidence {
  background-color: rgba(255, 68, 68, 0.2);
  border: 1px solid #ff4444;
  color: #ff4444;
  font-weight: bold;
}

.phoneme.high-confidence {
  background-color: rgba(68, 255, 68, 0.2);
  border: 1px solid #44ff44;
  color: #44ff44;
}

.phoneme.official {
  background-color: rgba(255, 255, 255, 0.1);
  border: 1px solid #ccc;
  color: #666;
}

/* Accuracy Gauge */
.accuracy-gauge {
  text-align: center;
  margin: 25px 0;
}
.gauge-circle {
  position: relative;
  width: 180px;
  height: 180px;
  margin: 0 auto;
}
.gauge-svg { transform: rotate(-90deg); }
.gauge-bg { stroke: rgba(255,255,255,0.3); }
.gauge-progress {
  stroke: url(#gaugeGradient);
  stroke-dasharray: 440;
  stroke-dashoffset: 440;
  transition: stroke-dashoffset 1.5s ease;
}
.accuracy-number {
  position: absolute;
  top: 50%; left: 50%;
  transform: translate(-50%, -50%);
  font-size: 2.5em;
  font-weight: bold;
  color: #333;
}
  </style>
</head>
<body>

<div class="container">
  <div class="header">
    <h1>üéôÔ∏è Phonetic Analysis Studio</h1>
    <p>High-Quality Voice Recording & Pronunciation Analysis</p>
  </div>

  <div class="recording-section">
    <button id="startBtn" class="btn" onclick="startRecording()">üé§ Start Recording</button>
    <button id="stopBtn" class="btn" onclick="stopRecording()" disabled>‚èπÔ∏è Stop Recording</button>
    <div id="status" class="status ready">Ready to record</div>
  </div>

  <div id="results" class="results hidden">
    <div class="transcription">
      <h3>üìù Transcription:</h3>
      <p id="transcriptionText">Your spoken text will appear here...</p>
    </div>

    <div class="pronunciation-comparison">
      <h3>üîä Pronunciation Comparison</h3>
      <div class="pronunciation-row">
        <span class="pronunciation-label">Your pronunciation:</span>
        <div class="pronunciation-text" id="yourPronunciation"></div>
      </div>
      <div class="pronunciation-row">
        <span class="pronunciation-label">Standard pronunciation:</span>
        <div class="pronunciation-text" id="officialPronunciation"></div>
      </div>
    </div>

    <div class="accuracy-gauge">
      <h3>üéØ Pronunciation Accuracy</h3>
      <div class="gauge-circle">
        <svg class="gauge-svg" width="180" height="180">
          <defs>
            <linearGradient id="gaugeGradient" x1="0%" y1="0%" x2="100%" y2="100%">
              <stop offset="0%" style="stop-color:#4facfe;stop-opacity:1" />
              <stop offset="100%" style="stop-color:#00f2fe;stop-opacity:1" />
            </linearGradient>
          </defs>
          <circle class="gauge-bg" cx="90" cy="90" r="70" stroke-width="12" fill="none"/>
          <circle id="ring" class="gauge-progress" cx="90" cy="90" r="70" stroke-width="12" fill="none"/>
        </svg>
        <div id="accuracyNumber" class="accuracy-number">0%</div>
      </div>
    </div>

    <div class="conversation-history">
      <h3>üí¨ Conversation History</h3>
      <div id="conversationList" class="conversation-list">
        <!-- Conversation items will be inserted here -->
      </div>
    </div>

    <div class="ai-response">
      <h3>ü§ñ AI Response</h3>
      <div id="aiResponse" class="ai-text">AI response will appear here...</div>
      <button id="playAiAudio" class="play-btn" style="display: none;">üîä Play AI Response</button>
    </div>

  </div>
</div>

  <script>
// ========== AUDIO WORKLET PROCESSOR CODE ==========
const audioWorkletCode = `
class RecorderProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.isRecording = false;
    this.port.onmessage = (e) => {
      if (e.data === 'start') {
        this.isRecording = true;
      } else if (e.data === 'stop') {
        this.isRecording = false;
      }
    };
  }

  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (this.isRecording && input && input[0]) {
      // Send audio data to main thread
      this.port.postMessage({
        channelData: input[0]
      });
    }
    return true;
  }
}

registerProcessor('recorder-processor', RecorderProcessor);
`;

// ========== GLOBAL VARIABLES ==========
let mediaStream = null;
let audioContext = null;
let audioWorkletNode = null;
let recordedChunks = [];
let isRecording = false;
let sessionId = 'session_' + Date.now();
let conversationHistory = [];
let currentAiAudio = null;

// DOM elements
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const statusEl = document.getElementById('status');
const results = document.getElementById('results');
const transcriptionText = document.getElementById('transcriptionText');
const ring = document.getElementById('ring');
const accuracyNumber = document.getElementById('accuracyNumber');
const conversationList = document.getElementById('conversationList');
const aiResponse = document.getElementById('aiResponse');
const playAiAudio = document.getElementById('playAiAudio');

// ========== START RECORDING WITH HIGHEST QUALITY ==========
async function startRecording() {
  try {
    console.log('üé§ Requesting microphone access...');
    
    // Request microphone with MAXIMUM quality settings
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        // Core quality settings
        sampleRate: { ideal: 48000, min: 44100 },
        sampleSize: { ideal: 24, min: 16 },
        channelCount: 1,
        
        // Disable ALL processing
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
        
        // Additional quality hints
        latency: 0,
        volume: 1.0
      }
    });

    // Log actual settings
    const audioTrack = mediaStream.getAudioTracks()[0];
    const settings = audioTrack.getSettings();
    console.log('üìä Microphone settings:', {
      sampleRate: settings.sampleRate,
      sampleSize: settings.sampleSize,
      channelCount: settings.channelCount,
      echoCancellation: settings.echoCancellation,
      noiseSuppression: settings.noiseSuppression,
      autoGainControl: settings.autoGainControl
    });

    // Create AudioContext with high sample rate
    audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: 48000,
      latencyHint: 'interactive'
    });

    console.log('üéµ AudioContext:', audioContext.sampleRate, 'Hz');

    // Create AudioWorklet for processing
    const blob = new Blob([audioWorkletCode], { type: 'application/javascript' });
    const workletUrl = URL.createObjectURL(blob);
    
    await audioContext.audioWorklet.addModule(workletUrl);
    URL.revokeObjectURL(workletUrl);

    // Setup audio processing chain
    const source = audioContext.createMediaStreamSource(mediaStream);
    audioWorkletNode = new AudioWorkletNode(audioContext, 'recorder-processor');

    // Collect audio data
    recordedChunks = [];
    audioWorkletNode.port.onmessage = (event) => {
      if (event.data.channelData) {
        const chunk = new Float32Array(event.data.channelData);
        recordedChunks.push(chunk);
      }
    };

    // Connect the chain
    source.connect(audioWorkletNode);
    audioWorkletNode.connect(audioContext.destination);

    // Start recording
    audioWorkletNode.port.postMessage('start');
    isRecording = true;

    // Update UI
    startBtn.disabled = true;
    stopBtn.disabled = false;
    startBtn.classList.add('recording');
    statusEl.textContent = 'Recording...';
    statusEl.className = 'status recording';

    console.log('‚úÖ Recording started');

  } catch (error) {
    console.error('‚ùå Recording error:', error);
    statusEl.textContent = 'Microphone access denied: ' + error.message;
    statusEl.className = 'status error';
  }
}

// ========== STOP RECORDING ==========
async function stopRecording() {
  if (!isRecording) return;

  console.log('üõë Stopping recording...');

  // Stop recording
  isRecording = false;
  if (audioWorkletNode) {
    audioWorkletNode.port.postMessage('stop');
  }

  // Update UI
  startBtn.disabled = false;
  stopBtn.disabled = true;
  startBtn.classList.remove('recording');
  statusEl.textContent = 'Processing...';
  statusEl.className = 'status processing';

  // Process the recorded audio
  await processRecordedAudio();

  // Cleanup
  if (audioWorkletNode) {
    audioWorkletNode.disconnect();
    audioWorkletNode = null;
  }
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
    mediaStream = null;
  }
  if (audioContext) {
    await audioContext.close();
    audioContext = null;
  }
}

// ========== PROCESS RECORDED AUDIO ==========
async function processRecordedAudio() {
  try {
    if (recordedChunks.length === 0) {
      throw new Error('No audio data recorded');
    }

    // Calculate total length
    const totalLength = recordedChunks.reduce((sum, chunk) => sum + chunk.length, 0);
    console.log('üéµ Total samples:', totalLength);
    console.log('üéµ Chunks:', recordedChunks.length);

    // Combine all chunks
    const combinedBuffer = new Float32Array(totalLength);
    let offset = 0;
    for (const chunk of recordedChunks) {
      combinedBuffer.set(chunk, offset);
      offset += chunk.length;
    }

    const sampleRate = 48000;
    const duration = totalLength / sampleRate;
    console.log('‚è±Ô∏è  Duration:', duration.toFixed(2), 'seconds');

    // Convert to WAV
    const wavBlob = encodeWAV(combinedBuffer, sampleRate);
    console.log('üíæ WAV size:', (wavBlob.size / 1024).toFixed(2), 'KB');
    console.log('üìä Format: 48kHz, 16-bit, mono, PCM WAV');

    // Send to server
    await analyzeAudio(wavBlob);

  } catch (error) {
    console.error('‚ùå Processing error:', error);
    statusEl.textContent = 'Error processing audio: ' + error.message;
    statusEl.className = 'status error';
  }
}

// ========== ENCODE TO WAV ==========
function encodeWAV(samples, sampleRate) {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);

  const writeString = (offset, string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };

  // WAV header
  writeString(0, 'RIFF');
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(8, 'WAVE');
  writeString(12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, 1, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true);
  view.setUint16(34, 16, true);
  writeString(36, 'data');
  view.setUint32(40, samples.length * 2, true);

  // Convert to 16-bit PCM
  let offset = 44;
  for (let i = 0; i < samples.length; i++) {
    const s = Math.max(-1, Math.min(1, samples[i]));
    const val = s < 0 ? s * 0x8000 : s * 0x7FFF;
    view.setInt16(offset, val, true);
    offset += 2;
  }

  return new Blob([buffer], { type: 'audio/wav' });
}

// ========== SEND TO SERVER ==========
async function analyzeAudio(blob) {
  const formData = new FormData();
  formData.append('file', blob, 'audio.wav');
  formData.append('session_id', sessionId);

  try {
    const res = await fetch('/align', { 
      method: 'POST', 
      body: formData 
    });
    
    const data = await res.json();

    if (res.ok) {
      displayResults(data);
    } else {
      statusEl.textContent = 'Server error: ' + (data.error || 'Unknown error');
      statusEl.className = 'status error';
    }
  } catch (error) {
    console.error('‚ùå Upload error:', error);
    statusEl.textContent = 'Network error: ' + error.message;
    statusEl.className = 'status error';
  }
}

// ========== DISPLAY RESULTS ==========
function displayResults(data) {
  results.classList.remove('hidden');
  statusEl.textContent = 'Analysis complete!';
  statusEl.className = 'status ready';
  
  transcriptionText.textContent = data.transcribed_text || '[No text detected]';

  // Display phoneme analysis with confidence highlighting
  displayPhonemeAnalysis(data.phoneme_analysis, data.accuracy_score);
  animateAccuracy(data.accuracy_score);
  
  // Update conversation history
  if (data.conversation_history) {
    conversationHistory = data.conversation_history;
    displayConversationHistory(conversationHistory);
  }
  
  // Display AI response
  if (data.ai_response) {
    aiResponse.textContent = data.ai_response;
    playAiAudio.style.display = 'inline-block';
    
    if (data.ai_audio) {
      currentAiAudio = new Audio('data:audio/mpeg;base64,' + data.ai_audio);
      playAiAudio.onclick = () => {
        if (currentAiAudio.paused) {
          currentAiAudio.play();
          playAiAudio.textContent = '‚è∏Ô∏è Pause AI Response';
        } else {
          currentAiAudio.pause();
          playAiAudio.textContent = 'üîä Play AI Response';
        }
      };
      
      currentAiAudio.onended = () => {
        playAiAudio.textContent = 'üîä Play AI Response';
      };
    } else {
      playAiAudio.style.display = 'none';
    }
  } else {
    aiResponse.textContent = 'No AI response available';
    playAiAudio.style.display = 'none';
  }
}

function displayPronunciationComparison(results) {
  const yourEl = document.getElementById('yourPronunciation');
  const offEl = document.getElementById('officialPronunciation');
  const space = '&nbsp;&nbsp;';

  const yourHTML = results.map(r =>
    `<span>${r.detected.map((p,i)=>`<span class="${r.errors.some(e=>e.index===i)?'phoneme-error':'phoneme-correct'}">${p}</span>`).join(' ')}</span>`
  ).join(space);

  const offHTML = results.map(r =>
    `<span>${r.standard.map(p=>`<span class="phoneme-correct">${p}</span>`).join(' ')}</span>`
  ).join(space);

  yourEl.innerHTML = yourHTML;
  offEl.innerHTML = offHTML;
}

function displayPhonemeAnalysis(phonemeAnalysis, accuracyScore) {
  const yourPronunciation = document.getElementById('yourPronunciation');
  const officialPronunciation = document.getElementById('officialPronunciation');
  
  if (!phonemeAnalysis || phonemeAnalysis.length === 0) {
    yourPronunciation.innerHTML = '<span style="color: #999;">No phoneme data available</span>';
    officialPronunciation.innerHTML = '<span style="color: #999;">No phoneme data available</span>';
    return;
  }
  
  // Display detected phonemes with confidence highlighting
  let yourHTML = '';
  let officialHTML = '';
  
  for (const phonemeData of phonemeAnalysis) {
    const { phoneme, posterior } = phonemeData;
    
    // Check if phoneme has low confidence (posterior < 0.1)
    const isLowConfidence = posterior < 0.2;
    
    // Your pronunciation with confidence highlighting
    const confidenceClass = isLowConfidence ? 'low-confidence' : 'high-confidence';
    const confidenceColor = isLowConfidence ? '#ff4444' : '#44ff44';
    
    yourHTML += `<span class="phoneme ${confidenceClass}" style="color: ${confidenceColor}; font-weight: bold;" title="Confidence: ${(posterior * 100).toFixed(1)}%">${phoneme}</span> `;
    
    // Official pronunciation (same phoneme, no highlighting)
    officialHTML += `<span class="phoneme official">${phoneme}</span> `;
  }
  
  yourPronunciation.innerHTML = yourHTML;
  officialPronunciation.innerHTML = officialHTML;
  
  // Update accuracy display
  console.log(`üìä Phoneme Analysis: ${phonemeAnalysis.length} phonemes, ${accuracyScore.toFixed(1)}% accuracy`);
}

function displayConversationHistory(history) {
  conversationList.innerHTML = history.map((item, index) => {
    const timestamp = new Date().toLocaleTimeString();
    return `
      <div class="conversation-item ${item.role}">
        <div class="role">${item.role === 'user' ? 'You' : 'AI'}</div>
        <div class="content">${item.content}</div>
        <div class="timestamp">${timestamp}</div>
      </div>
    `;
  }).join('');
  
  conversationList.scrollTop = conversationList.scrollHeight;
}


function animateAccuracy(val) {
  const percent = Math.max(0, Math.min(val, 100));
  const offset = 440 - (440 * percent) / 100;
  ring.style.strokeDashoffset = offset;
  accuracyNumber.textContent = percent.toFixed(1) + '%';
}
  </script>
</body>
</html>